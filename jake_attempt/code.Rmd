1. Introduction
============

2. Process
=======
2.1 Data Preparation
----------------
### 2.1.1 Import Dataset
```{r}
raw <- read.csv('../ticdata2000.csv')
data <- raw # make a backup just in case
```
### 2.1.2 Modify Datatypes
```{r}
categorical_names <- grep('^m|^caravan', names(data))
data[,categorical_names] <- lapply(data[,categorical_names], as.factor)
```

2.2 Data Exploration
----------------
### 2.2.1 Summary EDA
```{r}
head(data)
str(data)
summary(data)
```

### 2.2.2 Univariate EDA

### Multivariate EDA: Explanatory vs Reponse
```{r}
require(ggplot2)
```

#### Categorical Variables
```{r}
for(i in 1:(ncol(data)-1)){
  
}
ggplot(data, aes(x=maanthui, fill=caravan)) +
  geom_bar()
```

#### Numeric Variables
```{r}

```

2.3 Data Selection
------------------
### PCA
```{r}
pca <- princomp(data[,-86])
```


2.4 Modeling
------------
### Split Test/Train
```{r}
data$set <- 'Train'
rand <- sample(1:10, nrow(data), replace=T)
data[rand>8, 'set'] <- 'Test'
```
Let's look at the breakdown of the response variable between the two sets to make sure there's good coverage in both:
```{r}
table(data$set, data$caravan)
```
We see that the training set is sufficiently large, while the test set has a good number of observations where _caravan_ = 1. Let's split these into their own sets for easier usage.
```{r}
train <- data[data$set=='Train',-87]
test.x <- data[data$set=='Test',1:85]
test.y <- data[data$set=='Test',86]
```

### Define Formula
We have to define the formula that we're modeling upon first. We can do this by joining the column names together into a string, and then converting that string into the "formula" object.
```{r}
y <- names(data)[86]
x <- paste(names(data)[categorical_names], collapse='+')
f <- as.formula(paste(y, x, sep='~'))
```
We now have the formula, shown below:
```{r}
print(f)
```

### Logistic Regression
```{r}
lrm <- glm(f, train, family=binomial)
```

### Decision Tree
```{r}
require(rpart)
dt <- rpart(f, data, method='class')
printcp(dt)
```

### Naive Bayes
```{r}

```

1. Introduction
============


2. Process
=======
2.1 Data Preparation
----------------
### 2.1.1 Import Dataset
```{r}
library(kernlab)
data(ticdata)
#raw <- read.csv('../ticdata2000.csv')
data <- ticdata[1:5822,]
```
### 2.1.2 Modify Datatypes
```{r}
#categorical_names <- grep('^m|^caravan', names(data)) # not needed for kernlab
#data[,categorical_names] <- lapply(data[,categorical_names], as.factor)
dc <- as.data.frame(lapply(data, as.factor)) # transform all to categorical

str(dc)
head(dc)
```

```{r}
set.seed(123)
mask <- sample(5822,4075)

train <- dc[mask,]
test <- dc[-mask,]
```


2.2 Data Exploration
----------------
### 2.2.1 Summary EDA
```{r}
summary(dc)
```

### 2.2.2 Univariate EDA

### Multivariate EDA: Explanatory vs Reponse
```{r, fig.width=4, fig.height=3}
require(ggplot2)
for(i in 1:85){
  p <- ggplot(dc, aes(x=dc[,i], fill=CARAVAN)) +
    geom_bar()
  print(p)
}
```

### Corrgram
```{#r}
require(corrgram)
corrgram(dc[1:5,])
```
### Association Plot
```{r, fig.width=4, fig.height=4}
require(vcd)
for(i in 1:85){
  t <- table(dc[,c(i, 86)])
  assoc(t, shade=T)
}
```

### Decision Tree EDA
```{r, fig.width=10, fig.height=10}
require(rpart)
dt <- rpart(CARAVAN~., dc)

summary(dt)
printcp(dt)
plotcp(dt)

plot(dt, uniform=TRUE, main="Classification Tree for Caravan")
text(dt, use.n=TRUE, all=TRUE, cex=0.8)
```
It looks like the tree cannot differentiate between 

2.3 Data Selection
------------------
### PCA
```{#r}
pca <- princomp(data[1:100,1:5])
```


2.4 Modeling
------------
### Split Test/Train
```{#r}
data$set <- 'Train'
rand <- sample(1:10, nrow(data), replace=T)
data[rand>8, 'set'] <- 'Test'
```
Let's look at the breakdown of the response variable between the two sets to make sure there's good coverage in both:
```{#r}
table(data$set, data$caravan)
```
We see that the training set is sufficiently large, while the test set has a good number of observations where _caravan_ = 1. Let's split these into their own sets for easier usage.
```{#r}
train <- data[data$set=='Train',-87]
test.x <- data[data$set=='Test',1:85]
test.y <- data[data$set=='Test',86]
```

### Define Formula
We have to define the formula that we're modeling upon first. We can do this by joining the column names together into a string, and then converting that string into the "formula" object.
```{#r}
y <- names(data)[86]
x <- paste(names(data)[categorical_names], collapse='+')
f <- as.formula(paste(y, x, sep='~'))
```
We now have the formula, shown below:
```{#r}
print(f)
```

### Logistic Regression
```{#r}
lrm <- glm(f, train, family=binomial)
```

### Decision Tree
```{#r}
require(rpart)
dt <- rpart(f, data, method='class')
printcp(dt)
```

### Random Forest
```{r}

```


### Naive Bayes
```{r}

```
